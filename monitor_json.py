#!/usr/bin/env python3
"""
Arc'teryx Outlet ç›‘æ§å·¥å…· - JSON ç‰ˆï¼ˆç›´æ¥æå– Next.js æ•°æ®ï¼‰
"""

import os
import json
import time
import logging
import re
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# é…ç½®
TARGET_URL = "https://outlet.arcteryx.com/ca/zh/c/mens"
DATA_DIR = "data"
LOGS_DIR = "logs"
BASELINE_FILE = os.path.join(DATA_DIR, "baseline.json")

def ensure_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(LOGS_DIR, exist_ok=True)

def create_driver():
    """åˆ›å»ºä¼˜åŒ–çš„ Chrome WebDriver"""
    logger.info("æ­£åœ¨åˆå§‹åŒ– Chrome WebDriver...")
    
    chrome_options = Options()
    chrome_options.add_argument('--headless=new')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--disable-images')
    chrome_options.add_argument('--blink-settings=imagesEnabled=false')
    chrome_options.add_argument('--disable-extensions')
    chrome_options.add_argument('--window-size=1280,720')
    chrome_options.add_argument('--disable-software-rasterizer')
    chrome_options.add_argument('--remote-debugging-port=9222')  # æ·»åŠ è°ƒè¯•ç«¯å£
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
    
    # æ€§èƒ½ä¼˜åŒ–
    chrome_options.page_load_strategy = 'eager'  # ä¸ç­‰å¾…æ‰€æœ‰èµ„æºåŠ è½½å®Œæˆ
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        driver.set_script_timeout(15)
        logger.info("âœ“ Chrome WebDriver åˆå§‹åŒ–æˆåŠŸ")
        return driver
    except Exception as e:
        logger.error(f"âœ— åˆå§‹åŒ– WebDriver å¤±è´¥: {e}")
        raise

def fetch_products(driver, url):
    """è·å–å•†å“ä¿¡æ¯ï¼ˆé€šè¿‡æå– JSON æ•°æ®ï¼‰"""
    logger.info(f"æ­£åœ¨è®¿é—® {url}...")
    
    try:
        driver.get(url)
        logger.info("ç­‰å¾…é¡µé¢åŠ è½½...")
        
        # ç­‰å¾… body å…ƒç´ 
        wait = WebDriverWait(driver, 20)
        wait.until(EC.presence_of_element_located((By.TAG_NAME, 'body')))
        logger.info("âœ“ é¡µé¢å·²åŠ è½½")
        
        # è·å–é¡µé¢æºç 
        page_source = driver.page_source
        
        # æå– __NEXT_DATA__ JSON
        json_data = extract_next_data(page_source)
        
        if json_data:
            # è§£æäº§å“æ•°æ®
            products = parse_json_products(json_data)
            if products:
                logger.info(f"âœ“ æˆåŠŸæå– {len(products)} ä¸ªå•†å“")
                return products
        
        logger.warning("æœªèƒ½ä» JSON ä¸­æå–å•†å“æ•°æ®")
        return []
        
    except Exception as e:
        logger.error(f"è·å–å•†å“å¤±è´¥: {e}")
        return []

def extract_next_data(html):
    """ä» HTML ä¸­æå– __NEXT_DATA__ JSON"""
    try:
        # æŸ¥æ‰¾ <script id="__NEXT_DATA__" type="application/json">...</script>
        pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
        match = re.search(pattern, html, re.DOTALL)
        
        if match:
            json_str = match.group(1)
            data = json.loads(json_str)
            logger.info("âœ“ æˆåŠŸæå– __NEXT_DATA__ JSON")
            return data
        else:
            logger.warning("æœªæ‰¾åˆ° __NEXT_DATA__ JSON")
            return None
    except Exception as e:
        logger.error(f"è§£æ JSON å¤±è´¥: {e}")
        return None

def parse_json_products(data):
    """ä» JSON æ•°æ®ä¸­è§£æäº§å“"""
    products = []
    
    try:
        # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®è·¯å¾„
        paths = [
            ['props', 'pageProps', 'products'],
            ['props', 'pageProps', 'productList'],
            ['props', 'pageProps', 'items'],
            ['props', 'pageProps', 'data', 'products'],
            ['props', 'pageProps', 'catalog', 'products'],
        ]
        
        product_list = None
        for path in paths:
            try:
                current = data
                for key in path:
                    current = current[key]
                if current and isinstance(current, list):
                    product_list = current
                    logger.info(f"âœ“ åœ¨è·¯å¾„ {' -> '.join(path)} æ‰¾åˆ°äº§å“åˆ—è¡¨")
                    break
            except (KeyError, TypeError):
                continue
        
        if not product_list:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä¿å­˜ JSON ç”¨äºè°ƒè¯•
            with open('next_data_debug.json', 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info("JSON æ•°æ®å·²ä¿å­˜åˆ° next_data_debug.json ç”¨äºè°ƒè¯•")
            logger.warning("åœ¨é¢„å®šä¹‰è·¯å¾„ä¸­æœªæ‰¾åˆ°äº§å“åˆ—è¡¨")
            return []
        
        # è§£æäº§å“
        for item in product_list:
            try:
                product = {
                    'id': item.get('id') or item.get('productId') or item.get('sku'),
                    'name': item.get('name') or item.get('title') or item.get('productName'),
                    'price': item.get('price') or item.get('salePrice') or item.get('currentPrice'),
                    'link': item.get('url') or item.get('link') or item.get('href'),
                    'timestamp': datetime.now().isoformat()
                }
                
                # ç¡®ä¿æœ‰åŸºæœ¬ä¿¡æ¯
                if product['id'] or product['name']:
                    products.append(product)
            except Exception as e:
                logger.warning(f"è§£æå•ä¸ªäº§å“å¤±è´¥: {e}")
                continue
        
        return products
        
    except Exception as e:
        logger.error(f"è§£æäº§å“åˆ—è¡¨å¤±è´¥: {e}")
        return []

def save_data(products, filename=BASELINE_FILE):
    """ä¿å­˜æ•°æ®"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'products': products,
                'count': len(products),
                'timestamp': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ“ æ•°æ®å·²ä¿å­˜åˆ° {filename}")
        return True
    except Exception as e:
        logger.error(f"âœ— ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        return False

def load_baseline():
    """åŠ è½½åŸºå‡†æ•°æ®"""
    try:
        if os.path.exists(BASELINE_FILE):
            with open(BASELINE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('products', [])
        return []
    except Exception as e:
        logger.error(f"åŠ è½½åŸºå‡†æ•°æ®å¤±è´¥: {e}")
        return []

def compare_products(old_products, new_products):
    """æ¯”è¾ƒå•†å“å˜åŒ–"""
    old_ids = {p['id']: p for p in old_products if p.get('id')}
    new_ids = {p['id']: p for p in new_products if p.get('id')}
    
    # æ–°å¢å•†å“
    added = [p for pid, p in new_ids.items() if pid not in old_ids]
    
    # ä¸‹æ¶å•†å“
    removed = [p for pid, p in old_ids.items() if pid not in new_ids]
    
    # ä»·æ ¼å˜åŒ–
    price_changes = []
    for pid in set(old_ids.keys()) & set(new_ids.keys()):
        old_price = old_ids[pid].get('price')
        new_price = new_ids[pid].get('price')
        if old_price and new_price and old_price != new_price:
            price_changes.append({
                'product': new_ids[pid],
                'old_price': old_price,
                'new_price': new_price
            })
    
    return {
        'added': added,
        'removed': removed,
        'price_changes': price_changes
    }

def print_changes(changes):
    """æ‰“å°å˜åŒ–"""
    if changes['added']:
        logger.info(f"\nğŸ†• æ–°å¢å•†å“ ({len(changes['added'])}ä¸ª):")
        for p in changes['added'][:10]:
            logger.info(f"  - {p.get('name', 'N/A')} ({p.get('price', 'N/A')})")
    
    if changes['removed']:
        logger.info(f"\nğŸ“¦ ä¸‹æ¶å•†å“ ({len(changes['removed'])}ä¸ª):")
        for p in changes['removed'][:10]:
            logger.info(f"  - {p.get('name', 'N/A')}")
    
    if changes['price_changes']:
        logger.info(f"\nğŸ’° ä»·æ ¼å˜åŒ– ({len(changes['price_changes'])}ä¸ª):")
        for c in changes['price_changes'][:10]:
            logger.info(f"  - {c['product'].get('name', 'N/A')}: {c['old_price']} â†’ {c['new_price']}")
    
    if not any([changes['added'], changes['removed'], changes['price_changes']]):
        logger.info("\nâœ“ æ— å˜åŒ–")

def main():
    """ä¸»å‡½æ•°"""
    ensure_directories()
    
    logger.info("=" * 60)
    logger.info("Arc'teryx Outlet ç›‘æ§å·¥å…· - JSON ç‰ˆ")
    logger.info("=" * 60)
    
    driver = None
    try:
        # åˆ›å»ºé©±åŠ¨
        driver = create_driver()
        
        # è·å–å½“å‰å•†å“
        current_products = fetch_products(driver, TARGET_URL)
        
        if not current_products:
            logger.error("æœªèƒ½è·å–å•†å“æ•°æ®")
            return
        
        # åŠ è½½åŸºå‡†æ•°æ®
        baseline_products = load_baseline()
        
        if not baseline_products:
            # é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºåŸºå‡†
            logger.info("é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºåŸºå‡†æ•°æ®...")
            save_data(current_products)
        else:
            # æ¯”è¾ƒå˜åŒ–
            changes = compare_products(baseline_products, current_products)
            print_changes(changes)
            
            # æ›´æ–°åŸºå‡†
            save_data(current_products)
        
        logger.info("\nâœ“ ç›‘æ§å®Œæˆ")
        
    except Exception as e:
        logger.error(f"è¿è¡Œå‡ºé”™: {e}")
    finally:
        if driver:
            try:
                driver.quit()
                logger.info("âœ“ æµè§ˆå™¨å·²å…³é—­")
            except:
                pass

if __name__ == "__main__":
    main()

